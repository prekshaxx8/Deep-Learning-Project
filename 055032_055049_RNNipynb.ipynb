{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtfG2265a6Vb"
      },
      "source": [
        "# Reviews Sentiment analysis using Recurrent Neural Network\n",
        "\n",
        "\n",
        "Contributors:\n",
        "- Preksha Verma (055032)\n",
        "- Suvra DAtta Banik (055049)\n",
        "\n",
        "---\n",
        "## Objective\n",
        "\n",
        "To design, implement, and evaluate a deep learning-based sentiment analysis model using RNN architecture. This model aims to classify movie reviews based on sentiment by leveraging the sequential patterns present in text data.\n",
        "\n",
        "---\n",
        "\n",
        "## Problem Statement\n",
        "\n",
        "- Online movie reviews significantly influence public opinion.\n",
        "- Classifying sentiment is challenging due to language complexity.\n",
        "- The goal is to develop a machine learning model for sentiment analysis.\n",
        "- An RNN-based approach will be used to capture contextual information.\n",
        "- The model will classify reviews as positive, negative, or neutral.\n",
        "\n",
        "---\n",
        "\n",
        "## Key Tasks\n",
        "\n",
        "### 1. Data Preprocessing\n",
        "\n",
        "The data preprocessing stage prepares the movie review dataset to ensure compatibility with the RNN model. The key steps are:\n",
        "\n",
        "#### **I) Sentiment Encoding**\n",
        "- Positive Sentiment → Encoded as **1**\n",
        "- Negative Sentiment → Encoded as **0**\n",
        "\n",
        "#### **II) Text Normalization**\n",
        "- **Removing Special Characters:** Stripping unnecessary characters (e.g., punctuation, special symbols) to clean the text.\n",
        "- **Lowercasing:** Converting all reviews to lowercase for uniformity and consistency.\n",
        "\n",
        "#### **III) Tokenization**\n",
        "- Splitting the text into individual tokens (words).\n",
        "- Using a vocabulary size of **20,000** most frequent words (`max_features=20000`). Any words outside this range are replaced with a placeholder token.\n",
        "\n",
        "#### **IV) Sequence Padding**\n",
        "- Ensuring all tokenized reviews are of the same length by:\n",
        "  - Padding shorter sequences with zeros at the beginning or end.\n",
        "  - Truncating longer sequences to a maximum length of **400** tokens (`max_length = 400`).\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Model Development\n",
        "\n",
        "To build a model that classifies movie reviews as positive or negative, we follow these steps:\n",
        "\n",
        "#### **I) Using the Data**\n",
        "\n",
        "**Training Data:**\n",
        "- The training data consists of **50,000** records with the following **2 columns**:\n",
        "  - **Reviews:** The textual review of the movie.\n",
        "  - **Sentiment:** The sentiment label (positive or negative).\n",
        "- A random sample of **40,000** reviews is selected using a random state of **xxxx** to ensure reproducibility.\n",
        "\n",
        "**Dataset link:** IMDB Dataset of 50K Movie Reviews\n",
        "\n",
        "**Testing Data:**\n",
        "- The testing data consists of **151** records with the following **4 columns**:\n",
        "  - **Movie Name:** The title of the movie.\n",
        "  - **Rating:** The rating given to the movie.\n",
        "  - **Reviews:** The textual review of the movie.\n",
        "  - **Sentiment:** The sentiment label (positive or negative).\n",
        "- This dataset was created by manually scraping the data on reviews and ratings of various movies from **Metacritic**.\n",
        "\n",
        "#### **II) Model Structure**\n",
        "\n",
        "The model is built step by step with these layers:\n",
        "\n",
        "##### **Embedding Layer**\n",
        "- **Input dimension:** 20,000 (vocabulary size)\n",
        "- **Output dimension:** 128 (word embedding size)\n",
        "- **Input length:** 400 (maximum sequence length)\n",
        "\n",
        "##### **Recurrent Layer**\n",
        "- **Type:** SimpleRNN\n",
        "- **Number of units:** 64\n",
        "- **Activation function:** Tanh\n",
        "- **Return sequences:** False (since it’s a single RNN layer)\n",
        "- **Regularization:** Dropout (0.2) to prevent overfitting\n",
        "\n",
        "##### **Fully Connected Layer**\n",
        "- **Type:** Dense layer\n",
        "- **Number of neurons:** 1\n",
        "- **Activation function:** Sigmoid (for binary classification)\n",
        "\n",
        "#### **III) Training the Model**\n",
        "\n",
        "The model is trained on IMDB reviews by splitting the sampled dataset of **40,000** reviews into **80%** for training and **20%** for testing, ensuring the model learns effectively while being evaluated on unseen data during training.\n",
        "\n",
        "**Model Compilation and Training:**\n",
        "\n",
        "- **Loss Function:** Binary Crossentropy (suitable for binary classification)\n",
        "- **Optimizer:** Adam (learning rate = 0.001)\n",
        "- **Batch Size:** 32\n",
        "- **Epochs:** 15 (With early stopping)\n",
        "\n",
        "**Early Stopping Criteria:**\n",
        "- **Monitored metric:** Validation Loss\n",
        "- **Patience:** 3 epochs\n",
        "- **Best weights restored** if validation loss does not improve\n",
        "- The model was trained for **10** epochs initially and then for an additional **5** epochs.\n",
        "\n",
        "#### **IV) Testing the Model with Metacritic Data**\n",
        "- After training on IMDB reviews, the model is tested on the **100 manually collected Metacritic reviews**.\n",
        "- Performed data preprocessing, tokenization, and sequence padding as performed with the training dataset.\n",
        "\n",
        "#### **V) Predicting Sentiment for New Reviews**\n",
        "Once trained, the model can predict whether new reviews are **positive or negative**.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Observations\n",
        "\n",
        "- **Training accuracy** increased steadily, reaching approximately **89%** after **10 epochs**.\n",
        "- **Validation accuracy** remained stable at around **87%**, indicating good generalization.\n",
        "- The final **test accuracy** on the IMDB test set was around **86%**, suggesting a well-trained model with slight room for improvement.\n",
        "- Training loss started to decrease significantly with every epoch, with potential signs of overfitting mitigated by **early stopping and dropout**.\n",
        "- The model performed similarly on the Metacritic dataset, achieving a **test accuracy of approximately 77%**, showing that it generalizes well across different review datasets but could improve if **LSTM was used instead of RNN**.\n",
        "- Early stopping was triggered after a few epochs in both training phases, preventing overfitting and ensuring that the best model was retained.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Managerial Insights\n",
        "\n",
        "### **Model Effectiveness & Business Implications**\n",
        "- The RNN model performs well on the IMDB dataset but generalizes **poorly** on Metacritic reviews.\n",
        "- This suggests that Metacritic reviews might have **different writing styles, slang, or review structures** compared to IMDB.\n",
        "\n",
        "### **Improvement Areas**\n",
        "- **Better Preprocessing:** Introduce techniques like stemming, lemmatization, stop-word removal, and n-grams to improve accuracy.\n",
        "- **More Complex Architectures:** RNNs have limited long-term memory; switching to **LSTMs** may enhance generalization.\n",
        "- **Larger Dataset & Augmentation:** Training on a combined dataset of IMDB and Metacritic reviews may improve model robustness.\n",
        "- **Domain Adaptation:** Fine-tuning the model specifically on Metacritic reviews could improve cross-domain accuracy.\n",
        "\n",
        "### **Business Applications**\n",
        "- **Customer Sentiment Monitoring:** Companies can use this model to analyze movie, product, or service reviews to gauge public opinion.\n",
        "- **Brand Reputation Analysis:** Identifying sentiment trends can help businesses manage PR crises and improve customer engagement.\n",
        "- **Automated Review Filtering:** Businesses can filter out fake reviews or spam using an improved sentiment classification model.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Conclusion & Recommendations\n",
        "\n",
        "### **Immediate Steps:**\n",
        "- Improve text preprocessing by handling stop words and using TF-IDF weights.\n",
        "- Fine-tune the model using **transfer learning** with additional datasets.\n",
        "- Consider switching to **LSTM/GRU-based models** for improved generalization.\n",
        "\n",
        "### **Long-Term Strategy:**\n",
        "- Expand training data by incorporating reviews from multiple platforms.\n",
        "- Implement **real-time sentiment tracking** in a dashboard for actionable insights.\n",
        "- Conduct **A/B testing** with different architectures to find the best-performing model.\n",
        "\n",
        "By implementing these recommendations, the sentiment analysis model can achieve **higher accuracy (target: 75%+)** and be effectively deployed for business use cases.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8FnQSZINZaI"
      },
      "source": [
        "## 1. Importing the Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9XDI9fmFVaF"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding,Dropout\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kj3rB7p0N2T5"
      },
      "source": [
        "## 2. Preparing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gRBUPqTFzAp",
        "outputId": "52478942-34e8-42ed-bab3-f76de18b74c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns in the dataset:\n",
            "['review', 'sentiment']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pvsdb3249_data1 = pd.read_csv('IMDB Dataset.csv')\n",
        "print(\"Columns in the dataset:\")\n",
        "print(pvsdb3249_data1.columns.tolist())\n",
        "pvsdb3249_data1.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI4LIHSgFxnZ"
      },
      "source": [
        "### 2.1 Creating a random state of 40000 records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HTtZLNoHCeg"
      },
      "outputs": [],
      "source": [
        "pvsdb3249_data = pvsdb3249_data1.sample(n=40000, random_state=xxxx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjG-_V6lOaVd"
      },
      "source": [
        "### 2.2 Data cleaning and pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_NGDMjtGB9U"
      },
      "outputs": [],
      "source": [
        "pvsdb3249_data[\"review\"] = pvsdb3249_data[\"review\"].str.lower()\n",
        "pvsdb3249_data[\"review\"] = pvsdb3249_data[\"review\"].replace(r'[^a-z0-9\\s]', '', regex=True)\n",
        "\n",
        "pvsdb3249_data['sentiment value'] = pvsdb3249_data['sentiment'].apply(lambda x: 1 if x== \"positive\" else 0)\n",
        "pvsdb3249_data = pvsdb3249_data.dropna()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSUuitILO07u"
      },
      "source": [
        "### 2.3 Tokenizing and Padding of dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRGPp12dGKcw"
      },
      "outputs": [],
      "source": [
        "pvsdb3249_max_features = 20000\n",
        "pvsdb3249_max_length =400\n",
        "\n",
        "tokenizer = Tokenizer(num_words=pvsdb3249_max_features)\n",
        "tokenizer.fit_on_texts(pvsdb3249_data[\"review\"])\n",
        "X = pad_sequences(tokenizer.texts_to_sequences(pvsdb3249_data[\"review\"]), maxlen=pvsdb3249_max_length)\n",
        "y = pvsdb3249_data['sentiment value'].values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJSO3IOCPCWL"
      },
      "source": [
        "### 2.4 Spliting of dataset into test, train and validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKsc41H0GZw_"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.1, random_state=42, stratify=y_train\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4NsCCTXPmmF"
      },
      "source": [
        "## 3. Model Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf3xkbtmG4VH",
        "outputId": "b4c6dc84-f7ab-4926-980c-523853df9252"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "pvsdb3249_model1 = Sequential([\n",
        "    Embedding(input_dim=pvsdb3249_max_features, output_dim=128, input_length=pvsdb3249_max_length),\n",
        "    SimpleRNN(64, activation='tanh', return_sequences=False),\n",
        "    Dense(1, activation='sigmoid'),\n",
        "    Dropout(0.2),  # Helps prevent overfitting\n",
        "])\n",
        "\n",
        "pvsdb3249_model1.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNH_mgUwf2F8"
      },
      "source": [
        "### 3.1 Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fn-gYk0RsPc",
        "outputId": "be791d82-4664-42a0-b0fc-f0deb268f4c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 16 Complete [00h 10m 11s]\n",
            "val_accuracy: 0.8896874785423279\n",
            "\n",
            "Best val_accuracy So Far: 0.8909375071525574\n",
            "Total elapsed time: 02h 40m 47s\n",
            "\n",
            "Search: Running Trial #17\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "256               |256               |embedding_dim\n",
            "128               |128               |rnn_units\n",
            "0.3               |0.3               |dropout_1\n",
            "32                |32                |rnn_units_2\n",
            "0.2               |0.2               |dropout_2\n",
            "0.0001            |0.0001            |learning_rate\n",
            "10                |4                 |tuner/epochs\n",
            "4                 |2                 |tuner/initial_epoch\n",
            "2                 |2                 |tuner/bracket\n",
            "2                 |1                 |tuner/round\n",
            "0013              |0009              |tuner/trial_id\n",
            "\n",
            "Epoch 5/10\n",
            "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 402ms/step - accuracy: 0.9581 - loss: 0.1276 - val_accuracy: 0.8803 - val_loss: 0.3392\n",
            "Epoch 6/10\n",
            "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 389ms/step - accuracy: 0.9858 - loss: 0.0526 - val_accuracy: 0.8522 - val_loss: 0.4467\n",
            "Epoch 7/10\n",
            "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 379ms/step - accuracy: 0.9952 - loss: 0.0223 - val_accuracy: 0.8819 - val_loss: 0.4654\n",
            "Epoch 8/10\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_tuner\n",
        "import keras_tuner as kt\n",
        "def build_model(hp):\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=pvsdb3249_max_features, output_dim=hp.Choice('embedding_dim', [64, 128, 256]), input_length=pvsdb3249_max_length),\n",
        "        SimpleRNN(hp.Choice('rnn_units', [32, 64, 128]), return_sequences=True),\n",
        "        Dropout(hp.Choice('dropout_1', [0.2, 0.3, 0.5])),\n",
        "        SimpleRNN(hp.Choice('rnn_units_2', [32, 64]), return_sequences=False),\n",
        "        Dropout(hp.Choice('dropout_2', [0.2, 0.3, 0.5])),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(\n",
        "        loss='binary_crossentropy',\n",
        "        optimizer=Adam(learning_rate=hp.Choice('learning_rate', [0.001, 0.0005, 0.0001])),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Hyperparameter tuning\n",
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=10,\n",
        "    factor=3,\n",
        "    directory='tuner_dir',\n",
        "    project_name='sentiment_analysis'\n",
        ")\n",
        "\n",
        "tuner.search(X_train, y_train, epochs=10, validation_data=(X_val, y_val), batch_size=32)\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUYeTTYzPwol"
      },
      "source": [
        "### 3.2 Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQkDdZS6H1ca",
        "outputId": "806f2534-3d83-4a72-814b-27f89a661c85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 160ms/step - accuracy: 0.5266 - loss: 2.1433 - val_accuracy: 0.7753 - val_loss: 0.5031\n",
            "Epoch 2/10\n",
            "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 157ms/step - accuracy: 0.7352 - loss: 2.0097 - val_accuracy: 0.7613 - val_loss: 0.4937\n",
            "Epoch 3/10\n",
            "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 155ms/step - accuracy: 0.8067 - loss: 1.8844 - val_accuracy: 0.7613 - val_loss: 0.4844\n",
            "Epoch 4/10\n",
            "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 155ms/step - accuracy: 0.8092 - loss: 1.9229 - val_accuracy: 0.8409 - val_loss: 0.3988\n",
            "Epoch 5/10\n",
            "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 164ms/step - accuracy: 0.8481 - loss: 1.8207 - val_accuracy: 0.8731 - val_loss: 0.3375\n",
            "Epoch 6/10\n",
            "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 151ms/step - accuracy: 0.8621 - loss: 1.7406 - val_accuracy: 0.8800 - val_loss: 0.3195\n",
            "Epoch 7/10\n",
            "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 153ms/step - accuracy: 0.8759 - loss: 1.7111 - val_accuracy: 0.8747 - val_loss: 0.3098\n",
            "Epoch 8/10\n",
            "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 150ms/step - accuracy: 0.8857 - loss: 1.6764 - val_accuracy: 0.8725 - val_loss: 0.3160\n",
            "Epoch 9/10\n",
            "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 150ms/step - accuracy: 0.8835 - loss: 1.7258 - val_accuracy: 0.8709 - val_loss: 0.3213\n",
            "Epoch 10/10\n",
            "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 150ms/step - accuracy: 0.8951 - loss: 1.6280 - val_accuracy: 0.8741 - val_loss: 0.3318\n",
            "Test accuracy: 0.87\n"
          ]
        }
      ],
      "source": [
        "# commenting this since the model has been trained and saved\n",
        "# pvsdb3249_early_stopping = EarlyStopping(\n",
        "#     monitor='val_loss', patience=3, restore_best_weights=True\n",
        "# )\n",
        "\n",
        "# pvsdb3249_history11 = pvsdb3249_model1.fit(\n",
        "#     X_train, y_train,\n",
        "#     epochs=10,\n",
        "#     batch_size=32,\n",
        "#     validation_data=(X_val, y_val),\n",
        "#     callbacks=[pvsdb3249_early_stopping],  # Stops if validation loss doesn't improve\n",
        "#     verbose=1\n",
        "# )\n",
        "\n",
        "# pvsdb3249_score = pvsdb3249_model1.evaluate(X_test, y_test, verbose=0)\n",
        "# print(f\"Test accuracy: {pvsdb3249_score[1]:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0JQK6ue9AXA",
        "outputId": "17a3cff1-ff74-40f9-aab1-84975b4d8099"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 152ms/step - accuracy: 0.8839 - loss: 1.6686 - val_accuracy: 0.8766 - val_loss: 0.3009\n",
            "Epoch 2/5\n",
            "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 149ms/step - accuracy: 0.8861 - loss: 1.7064 - val_accuracy: 0.8659 - val_loss: 0.3450\n",
            "Epoch 3/5\n",
            "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 149ms/step - accuracy: 0.8902 - loss: 1.7007 - val_accuracy: 0.8653 - val_loss: 0.3486\n",
            "Epoch 4/5\n",
            "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 147ms/step - accuracy: 0.8921 - loss: 1.6961 - val_accuracy: 0.8741 - val_loss: 0.3630\n",
            "Test accuracy: 0.87\n"
          ]
        }
      ],
      "source": [
        "# commenting this since the model has been trained and saved\n",
        "# #running code for 5 more epochs\n",
        "pvsdb3249_history1 = pvsdb3249_model1.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=5,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=[pvsdb3249_early_stopping],  # Stops if validation loss doesn't improve\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# pvsdb3249_score = pvsdb3249_model1.evaluate(X_test, y_test, verbose=0)\n",
        "# print(f\"Test accuracy: {pvsdb3249_score[1]:.2f}\")\n",
        "# this accuracy is on the test data of IMDB Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MdZpDfASgx8"
      },
      "outputs": [],
      "source": [
        "pvsdb3249_model1.save('pvsdb3249_model12.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UpH7nV4QOHm"
      },
      "source": [
        "## 4. Loading Metacritic dataset for testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "kJltGW7J_zDp",
        "outputId": "638fc083-c741-4a4d-d7b0-a0e67622a815"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns in the dataset:\n",
            "['Movie Name', 'Rating', 'Review', 'sentiment']\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"kama2224_test_data1\",\n  \"rows\": 151,\n  \"fields\": [\n    {\n      \"column\": \"Movie Name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 26,\n        \"samples\": [\n          \"Harry Potter 7\",\n          \"Harry Potter 15\",\n          \"La La Land\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 10,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0,\n          10,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 146,\n        \"samples\": [\n          \"To be fair, I never read any of the books, so I can simply judge this based on that. Whether it is loyal to the source material or not is of no consequence to me. With that said, I really enjoyed this movie. It was fun. Sure it isn't as good as some of the earlier movies, and the acting still OK-ish, but I still thought it was entertaining.\",\n          \"Film with a pleasant plot and innovative narrative elements compared to the classic Marvel film\",\n          \"The second half of Harry's grand finale is better than the first, but still struggles to cope with too many characters, too little color and an overstuffed dance card. There's just so much going on, and it's all so excessively dim... Over-reliance upon book lore has been a long-term problem for this franchise, and that issue has only grown more pronounced as the film adaptations enter their final stretch. I have no idea how anyone could make sense of Deathly Hallows 2 without keeping a store of such information, fresh and reliable, somewhere in their noggin. Maybe a Cliff's Notes handbook and a hair-trigger pause button would suffice. Casually tossing about complicated concepts like wand allegiance, multiplying spells, hallows and horcruxes, the film skims along at a high speed, in breathless pursuit of flashier material. Of that, fortunately, there's plenty, and those bits are loaded with well-constructed callbacks to the previous films. The action scenes are constant highlights, excellent in concept and in execution; a fitting farewell, in their own way, for the series at large. Quieter character moments are more of a mixed bag. Snape gets his big spotlight scene, after being completely ignored in Part 1, but most of the younger cast members are swept up in the desperate search for a soul mate. Everybody just wants to pair off, to hit that convenient epilogue with a litter of kids tugging at their shoestrings. Despite simmering for years and years, in many cases, such romances play more like a series of checked boxes than natural, heartfelt outpourings of emotion. Ron and Hermione are a prime example. The moment of their long-germinating embrace was evidently a difficult scene for the actors, who literally grew up together on-set, and their discomfort is clear on the screen. The kiss feels like an awkward, instantly-regretted smooch between friends, not a grand culmination, and that robs power from these beloved characters' storybook ending. They probably should've got that out of the way several movies earlier anyway. Here, in the midst of a hectic chase and a frenzied battle, even an effective payoff would've been lost in the mix. Which is another recurring issue that this film never really settles. There's enough material for three movies in here (or a seven-hundred page book, as it were) and in trying to please everyone, to fit it all in, the whole package fades into a fleeting, dizzying wash. Nothing gets a chance to breathe, lest a different scene meet the cutting room floor. Crucial time is cut from meaningful points in the main narrative, dampening their impact, to cram in a few smaller, crowd-pleasing tidbits. But those, too, are over and done with so quickly that they hardly seem worth the effort. In the end, we get (nearly) everything, without necessitating another weird mid-stream cutaway, but nothing is half as rewarding as I'd expected. A stumble over the finish line, in other words; a film that hits the novel's plot points but completely misses its spirit. Could\\u0092ve been worse, I guess, but it also could\\u0092ve been so much better.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "kama2224_test_data1"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-47262b17-27c5-4b7f-9cdc-779332eb246b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Movie Name</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>La La Land</td>\n",
              "      <td>10</td>\n",
              "      <td>Damien Chazelles La La Land is a dazzling rom...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>La La Land</td>\n",
              "      <td>10</td>\n",
              "      <td>The song \"City of Stars\" as a duet encapsulate...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>La La Land</td>\n",
              "      <td>6</td>\n",
              "      <td>\"La La Land\" does combine Chazelle's fun camer...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>La La Land</td>\n",
              "      <td>3</td>\n",
              "      <td>I found this movie to be an insult to jazz. Th...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>La La Land</td>\n",
              "      <td>3</td>\n",
              "      <td>I didn't like the story much. It has some good...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>La La Land</td>\n",
              "      <td>9</td>\n",
              "      <td>... what have I done... I can never unsee this...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>La La Land</td>\n",
              "      <td>10</td>\n",
              "      <td>Damien Chazelle has created another beautiful ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>La La Land</td>\n",
              "      <td>10</td>\n",
              "      <td>I mean, it's just perfect. The musics, the sto...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>La La Land</td>\n",
              "      <td>10</td>\n",
              "      <td>Another musical masterpiece by chazelle, amazi...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Pinnochio</td>\n",
              "      <td>6</td>\n",
              "      <td>okay young Disney even though this bombed this...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47262b17-27c5-4b7f-9cdc-779332eb246b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-47262b17-27c5-4b7f-9cdc-779332eb246b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-47262b17-27c5-4b7f-9cdc-779332eb246b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b8a2360c-9c48-4c33-8da4-8aa168a7700d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b8a2360c-9c48-4c33-8da4-8aa168a7700d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b8a2360c-9c48-4c33-8da4-8aa168a7700d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   Movie Name  Rating                                             Review  \\\n",
              "0  La La Land      10  Damien Chazelles La La Land is a dazzling rom...   \n",
              "1  La La Land      10  The song \"City of Stars\" as a duet encapsulate...   \n",
              "2  La La Land       6  \"La La Land\" does combine Chazelle's fun camer...   \n",
              "3  La La Land       3  I found this movie to be an insult to jazz. Th...   \n",
              "4  La La Land       3  I didn't like the story much. It has some good...   \n",
              "5  La La Land       9  ... what have I done... I can never unsee this...   \n",
              "6  La La Land      10  Damien Chazelle has created another beautiful ...   \n",
              "7  La La Land      10  I mean, it's just perfect. The musics, the sto...   \n",
              "8  La La Land      10  Another musical masterpiece by chazelle, amazi...   \n",
              "9   Pinnochio       6  okay young Disney even though this bombed this...   \n",
              "\n",
              "  sentiment  \n",
              "0  positive  \n",
              "1  positive  \n",
              "2  positive  \n",
              "3  negative  \n",
              "4  negative  \n",
              "5  positive  \n",
              "6  positive  \n",
              "7  positive  \n",
              "8  positive  \n",
              "9  positive  "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pvsdb3249_test_data1 = pd.read_csv('metacritic test dataset1.csv', encoding='latin1')\n",
        "print(\"Columns in the dataset:\")\n",
        "print(pvsdb3249_test_data1.columns.tolist())\n",
        "pvsdb3249_test_data1.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Du5dsJDyQfWF"
      },
      "source": [
        "### 4.1 Data cleaning and pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89gI0p3D-kqi"
      },
      "outputs": [],
      "source": [
        "pvsdb3249_test_data1[\"Review\"] = pvsdb3249_test_data1[\"Review\"].str.lower()\n",
        "pvsdb3249_test_data1[\"Review\"] = pvsdb3249_test_data1[\"Review\"].replace(r'[^a-z0-9\\s]', '', regex=True)\n",
        "\n",
        "pvsdb3249_test_data1['sentiment value'] = pvsdb3249_test_data1['sentiment'].apply(lambda x: 1 if x== \"positive\" else 0)\n",
        "pvsdb3249_test_data1 = pvsdb3249_test_data1.dropna()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6zTuoh9Qj7X"
      },
      "source": [
        "### 4.2 Tokenizing and padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4QHVBbC-3mK"
      },
      "outputs": [],
      "source": [
        "\n",
        "# tokenizer = Tokenizer(num_words=20000)\n",
        "# tokenizer.fit_on_texts(pvsdb3249_test_data1[\"Review\"])\n",
        "X = pad_sequences(tokenizer.texts_to_sequences(pvsdb3249_test_data1[\"Review\"]), maxlen=pvsdb3249_max_length)\n",
        "y = pvsdb3249_test_data1['sentiment value'].values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfndDy9EQv0r"
      },
      "source": [
        "## 4.3 Accuracy on Metacritic test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73ic31uJCiSu",
        "outputId": "9c8b9e05-b573-4bfd-f8a1-d818eb7fbea3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.77\n"
          ]
        }
      ],
      "source": [
        "\n",
        "score = pvsdb3249_model1.evaluate(X, y, verbose=0)\n",
        "print(f\"Test accuracy: {score[1]:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jj3wBm7u9XN3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}